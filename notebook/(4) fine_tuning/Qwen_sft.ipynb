{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5553ac12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "import time\n",
    "import torch\n",
    "import json\n",
    "import gc\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "\n",
    "# Import our library components\n",
    "from transfer import Trainer, SFTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f65a99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import torch\n",
    "\n",
    "def clear_memory(extra_names=()):\n",
    "    \"\"\"\n",
    "    Aggressively free GPU memory across *all* CUDA devices.\n",
    "    Pass any extra global var names via extra_names if needed.\n",
    "    \"\"\"\n",
    "    # 0) Early exit if no CUDA\n",
    "    if not torch.cuda.is_available():\n",
    "        gc.collect()\n",
    "        return print(\"CUDA not available. Collected CPU garbage only.\")\n",
    "\n",
    "    # 1) Try to move known models off GPU (if still around)\n",
    "    for name in (\"model\", \"base_model\"):\n",
    "        obj = globals().get(name, None)\n",
    "        try:\n",
    "            if obj is not None and hasattr(obj, \"to\"):\n",
    "                obj.to(\"cpu\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # 2) Delete common globals (if present)\n",
    "    for name in (\"inputs\", \"base_model\", \"model\", \"tokenizer\", *extra_names):\n",
    "        globals().pop(name, None)\n",
    "\n",
    "    # 3) Delete any stray CUDA tensors lingering in globals()\n",
    "    for name, obj in list(globals().items()):\n",
    "        try:\n",
    "            if torch.is_tensor(obj) and obj.is_cuda:\n",
    "                del globals()[name]\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # 4) Full GC pass\n",
    "    gc.collect()\n",
    "    time.sleep(0.1)\n",
    "\n",
    "    # 5) Clear *each* CUDA device\n",
    "    for idx in range(torch.cuda.device_count()):\n",
    "        try:\n",
    "            with torch.cuda.device(idx):\n",
    "                torch.cuda.synchronize()\n",
    "                torch.cuda.empty_cache()\n",
    "                # Collect interprocess memory (helps when using multiple processes / dataloaders)\n",
    "                torch.cuda.ipc_collect()\n",
    "                # Reset peak stats (optional, for cleaner diagnostics)\n",
    "                try:\n",
    "                    torch.cuda.reset_peak_memory_stats(idx)\n",
    "                except Exception:\n",
    "                    pass\n",
    "        except Exception:\n",
    "            # Keep going even if one device throws\n",
    "            pass\n",
    "\n",
    "    # 6) One more GC + sync\n",
    "    gc.collect()\n",
    "    for idx in range(torch.cuda.device_count()):\n",
    "        try:\n",
    "            with torch.cuda.device(idx):\n",
    "                torch.cuda.synchronize()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # 7) Report per-device\n",
    "    for idx in range(torch.cuda.device_count()):\n",
    "        alloc = torch.cuda.memory_allocated(idx) / (1024 ** 3)\n",
    "        reserv = torch.cuda.memory_reserved(idx) / (1024 ** 3)\n",
    "        print(f\"cuda:{idx} -> allocated: {alloc:.2f} GB | reserved: {reserv:.2f} GB\")\n",
    "\n",
    "# run it\n",
    "# clear_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01b4653f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Dataset Configuration:\n",
      "- dataset_name: skk_dataset\n",
      "- train: {'type': 'json', 'path': 'dataset/ksmi_train_topic_modelled.jsonl'}\n",
      "- val: {'type': 'json', 'path': 'dataset/ksmi_val_topic_modelled.jsonl'}\n",
      "- train_rl: {'type': 'json', 'path': 'dataset/ksmi_train_rl_topic_modelled.jsonl'}\n",
      "- val_rl: {'type': 'json', 'path': 'dataset/ksmi_val_rl_topic_modelled.jsonl'}\n",
      "- test: {'type': 'json', 'path': 'dataset/ksmi_test_topic_modelled.jsonl'}\n",
      "- data_sft: {'input_field': ['instruction', 'input'], 'target_field': 'output'}\n",
      "- data_rl: {'input_field': 'prompt', 'chosen_field': 'chosen', 'rejected_field': 'rejected'}\n",
      "- prompt_template: # Question:\n",
      "{query_text}\n",
      "\n",
      "# Note:\n",
      "If the question contains technical terms use the RAG tools to get definitions first, DO NOT interpret the meaning by yourself! Then, create a plan to answer the user's question.\n",
      "\n",
      "Dataset Name: skk_dataset\n",
      "Train File: {'type': 'json', 'path': 'dataset/ksmi_train_topic_modelled.jsonl'}\n",
      "Validation File: {'type': 'json', 'path': 'dataset/ksmi_val_topic_modelled.jsonl'}\n",
      "Test File: {'type': 'json', 'path': 'dataset/ksmi_test_topic_modelled.jsonl'}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "def load_dataset_config(config_path):\n",
    "    \"\"\"\n",
    "    Loads a YAML configuration file for dataset fine-tuning.\n",
    "\n",
    "    Args:\n",
    "        config_path (str): The path to the YAML configuration file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the loaded configuration.\n",
    "    \"\"\"\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "# Example usage:\n",
    "config_file = 'skk_dataset_config.yaml'\n",
    "dataset_config = load_dataset_config(config_file)\n",
    "\n",
    "print(\"Loaded Dataset Configuration:\")\n",
    "for key, value in dataset_config.items():\n",
    "    print(f\"- {key}: {value}\")\n",
    "\n",
    "# Accessing specific parameters:\n",
    "print(f\"\\nDataset Name: {dataset_config['dataset_name']}\")\n",
    "print(f\"Train File: {dataset_config['train']}\")\n",
    "print(f\"Validation File: {dataset_config['val']}\")\n",
    "print(f\"Test File: {dataset_config['test']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11ec2fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'file_name', 'instruction', 'input', 'output', 'complexity', 'input_length', 'output_length', 'dominant_topic', 'topic_keywords', 'topic_name'],\n",
       "        num_rows: 2222\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['id', 'file_name', 'instruction', 'input', 'output', 'complexity', 'input_length', 'output_length', 'dominant_topic', 'topic_keywords', 'topic_name'],\n",
       "        num_rows: 247\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'output', 'dominant_topic', 'topic_keywords', 'topic_name'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import randrange\n",
    "from datasets import load_dataset, concatenate_datasets, DatasetDict\n",
    "\n",
    "# Load dataset from jsonl files specified in the config\n",
    "train_data = load_dataset(dataset_config['train']['type'], data_files={'train': dataset_config['train']['path']})\n",
    "val_data = load_dataset(dataset_config['val']['type'], data_files={'val': dataset_config['val']['path']})\n",
    "test_data = load_dataset(dataset_config['test']['type'], data_files={'test': dataset_config['test']['path']})\n",
    "\n",
    "# take 20 samples from train and test for quick testing\n",
    "# train_data['train'] = train_data['train'].select(range(1))\n",
    "# test_data['test'] = test_data['test'].shuffle(seed=42).select(range(20))\n",
    "\n",
    "combined_data = DatasetDict({\"train\": train_data['train'], \"val\": val_data['val'], \"test\": test_data['test']})\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1275f52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1529, 'file_name': 'ksmi_complex_dataset_full', 'instruction': 'Jelaskan alur yang tepat untuk memperbarui status kelas dan level pada akhir tahun ketika selama satu tahun proyek berpindah dari Prospect, menemukan hidrokarbon, mencapai Discovery under Evaluation, lalu mendapatkan persetujuan pengakhiran eksplorasi.', 'input': '', 'output': '## Alur Pembaruan Status Kelas dan Level Proyek Eksplorasi\\n\\nPembaruan status kelas dan level proyek eksplorasi pada akhir tahun mengikuti alur yang logis berdasarkan perkembangan data dan evaluasi yang dilakukan selama satu tahun. Dalam kasus ini, proyek dimulai dari tahap Prospect, menemukan hidrokarbon, mencapai Discovery under Evaluation, dan akhirnya mendapatkan persetujuan pengakhiran eksplorasi. Berikut adalah penjelasan rinci mengenai alur tersebut:\\n\\n### 1. Tahap Awal: Prospect\\nProyek pada awalnya berada di level Prospect, yaitu tahap di mana potensi akumulasi petroleum telah teridentifikasi berdasarkan data yang cukup untuk menentukan target pengeboran sumur eksplorasi. Data yang mendukung tahap ini dapat berupa seismik 3D atau data lain yang relevan, meskipun tidak selalu diperlukan tergantung pada kondisi geologi. Pada tahap ini, proyek belum pernah dibor, sehingga keberadaan akumulasi hidrokarbon belum terkonfirmasi.\\n\\nSetelah pengeboran dilakukan, proyek dapat melanjutkan ke tahap evaluasi aliran (flow evaluation). Jika pengeboran berhasil menemukan hidrokarbon, proyek akan berpindah ke tahap berikutnya. Namun, jika pengeboran tidak menemukan hidrokarbon, proyek akan dikategorikan sebagai Dry dan masuk ke kategori Abandoned.\\n\\n### 2. Penemuan Hidrokarbon: Discovery under Evaluation\\nSetelah hidrokarbon ditemukan melalui pengeboran, proyek memasuki tahap Discovery under Evaluation. Pada tahap ini, keberadaan akumulasi petroleum telah dikonfirmasi secara konklusif, biasanya melalui uji sumur atau metode lain yang disepakati oleh pihak berwenang. Keyakinan bahwa fluida dapat mengalir secara terus-menerus ke permukaan menjadi kunci untuk menetapkan proyek pada level ini. \\n\\nProyek hanya dapat berada di tahap Discovery under Evaluation selama maksimum dua WAP (Waktu Acuan Pelaporan). Selama tahap ini, biasanya dilakukan pengeboran delineasi untuk mengkonfirmasi batas akumulasi petroleum dan mengevaluasi strategi pengembangan lapangan. Jika evaluasi selesai dan proyek mendapatkan persetujuan pengakhiran eksplorasi, maka proyek dapat berpindah ke tahap berikutnya.\\n\\n### 3. Persetujuan Pengakhiran Eksplorasi: Development Pending\\nSetelah mendapatkan persetujuan pengakhiran eksplorasi, proyek berpindah ke tahap Development Pending. Pada tahap ini, strategi pengembangan lapangan sedang disusun dan dievaluasi. Persetujuan pengakhiran eksplorasi merupakan dokumen penting yang diperlukan untuk transisi dari tahap Discovery under Evaluation ke tahap Development Pending. \\n\\nProyek pada tahap ini memiliki peluang untuk melanjutkan ke fase eksploitasi jika strategi pengembangan lapangan disetujui oleh pihak berwenang. Jika rencana pengembangan lapangan disetujui, proyek dapat naik ke level Justified for Development dan berpindah ke fase eksploitasi. Namun, jika rencana pengembangan ditolak, proyek dapat turun ke level Development Not Viable atau kembali ke tahap Development Undetermined jika membutuhkan data tambahan.\\n\\n### Kesimpulan\\nAlur pembaruan status kelas dan level proyek eksplorasi selama satu tahun mencerminkan kemajuan yang signifikan dari tahap Prospect hingga Development Pending. Proses ini melibatkan pengeboran, evaluasi aliran, konfirmasi akumulasi hidrokarbon, dan penyusunan strategi pengembangan lapangan. Setiap transisi antar level didasarkan pada data dan evaluasi yang dilakukan, serta keputusan dari pihak berwenang. Dengan demikian, pembaruan status pada akhir tahun harus mencerminkan status terakhir proyek sesuai dengan perkembangan yang terjadi selama periode pelaporan.', 'complexity': 0.7312404987, 'input_length': 69, 'output_length': 1005, 'dominant_topic': 4, 'topic_keywords': 'pengembangan, eksplorasi, development, fase, berproduksi', 'topic_name': 'pengembangan, eksplorasi, development, fase, berproduksi'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'file_name', 'instruction', 'input', 'output', 'complexity', 'input_length', 'output_length', 'dominant_topic', 'topic_keywords', 'topic_name'],\n",
       "    num_rows: 2222\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = combined_data['train']\n",
    "dataset_size = len(combined_data['train'])\n",
    "print(combined_data['train'][0])\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0655ad4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1529,\n",
       " 'file_name': 'ksmi_complex_dataset_full',\n",
       " 'prompt': 'Jelaskan alur yang tepat untuk memperbarui status kelas dan level pada akhir tahun ketika selama satu tahun proyek berpindah dari Prospect, menemukan hidrokarbon, mencapai Discovery under Evaluation, lalu mendapatkan persetujuan pengakhiran eksplorasi.',\n",
       " 'input': '',\n",
       " 'response': '## Alur Pembaruan Status Kelas dan Level Proyek Eksplorasi\\n\\nPembaruan status kelas dan level proyek eksplorasi pada akhir tahun mengikuti alur yang logis berdasarkan perkembangan data dan evaluasi yang dilakukan selama satu tahun. Dalam kasus ini, proyek dimulai dari tahap Prospect, menemukan hidrokarbon, mencapai Discovery under Evaluation, dan akhirnya mendapatkan persetujuan pengakhiran eksplorasi. Berikut adalah penjelasan rinci mengenai alur tersebut:\\n\\n### 1. Tahap Awal: Prospect\\nProyek pada awalnya berada di level Prospect, yaitu tahap di mana potensi akumulasi petroleum telah teridentifikasi berdasarkan data yang cukup untuk menentukan target pengeboran sumur eksplorasi. Data yang mendukung tahap ini dapat berupa seismik 3D atau data lain yang relevan, meskipun tidak selalu diperlukan tergantung pada kondisi geologi. Pada tahap ini, proyek belum pernah dibor, sehingga keberadaan akumulasi hidrokarbon belum terkonfirmasi.\\n\\nSetelah pengeboran dilakukan, proyek dapat melanjutkan ke tahap evaluasi aliran (flow evaluation). Jika pengeboran berhasil menemukan hidrokarbon, proyek akan berpindah ke tahap berikutnya. Namun, jika pengeboran tidak menemukan hidrokarbon, proyek akan dikategorikan sebagai Dry dan masuk ke kategori Abandoned.\\n\\n### 2. Penemuan Hidrokarbon: Discovery under Evaluation\\nSetelah hidrokarbon ditemukan melalui pengeboran, proyek memasuki tahap Discovery under Evaluation. Pada tahap ini, keberadaan akumulasi petroleum telah dikonfirmasi secara konklusif, biasanya melalui uji sumur atau metode lain yang disepakati oleh pihak berwenang. Keyakinan bahwa fluida dapat mengalir secara terus-menerus ke permukaan menjadi kunci untuk menetapkan proyek pada level ini. \\n\\nProyek hanya dapat berada di tahap Discovery under Evaluation selama maksimum dua WAP (Waktu Acuan Pelaporan). Selama tahap ini, biasanya dilakukan pengeboran delineasi untuk mengkonfirmasi batas akumulasi petroleum dan mengevaluasi strategi pengembangan lapangan. Jika evaluasi selesai dan proyek mendapatkan persetujuan pengakhiran eksplorasi, maka proyek dapat berpindah ke tahap berikutnya.\\n\\n### 3. Persetujuan Pengakhiran Eksplorasi: Development Pending\\nSetelah mendapatkan persetujuan pengakhiran eksplorasi, proyek berpindah ke tahap Development Pending. Pada tahap ini, strategi pengembangan lapangan sedang disusun dan dievaluasi. Persetujuan pengakhiran eksplorasi merupakan dokumen penting yang diperlukan untuk transisi dari tahap Discovery under Evaluation ke tahap Development Pending. \\n\\nProyek pada tahap ini memiliki peluang untuk melanjutkan ke fase eksploitasi jika strategi pengembangan lapangan disetujui oleh pihak berwenang. Jika rencana pengembangan lapangan disetujui, proyek dapat naik ke level Justified for Development dan berpindah ke fase eksploitasi. Namun, jika rencana pengembangan ditolak, proyek dapat turun ke level Development Not Viable atau kembali ke tahap Development Undetermined jika membutuhkan data tambahan.\\n\\n### Kesimpulan\\nAlur pembaruan status kelas dan level proyek eksplorasi selama satu tahun mencerminkan kemajuan yang signifikan dari tahap Prospect hingga Development Pending. Proses ini melibatkan pengeboran, evaluasi aliran, konfirmasi akumulasi hidrokarbon, dan penyusunan strategi pengembangan lapangan. Setiap transisi antar level didasarkan pada data dan evaluasi yang dilakukan, serta keputusan dari pihak berwenang. Dengan demikian, pembaruan status pada akhir tahun harus mencerminkan status terakhir proyek sesuai dengan perkembangan yang terjadi selama periode pelaporan.',\n",
       " 'complexity': 0.7312404987,\n",
       " 'input_length': 69,\n",
       " 'output_length': 1005,\n",
       " 'dominant_topic': 4,\n",
       " 'topic_keywords': 'pengembangan, eksplorasi, development, fase, berproduksi',\n",
       " 'topic_name': 'pengembangan, eksplorasi, development, fase, berproduksi'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.rename_column(\"instruction\", \"prompt\")\n",
    "train_data = train_data.rename_column(\"output\", \"response\")\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f51e4f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 2119, 'file_name': 'ksmi_complex_dataset_full', 'instruction': 'Jelaskan bagaimana faktor teknologi produksi (misalnya fracking) memengaruhi keyakinan alir konklusif dan mengubah status proyek, serta bagaimana perubahan ini menggeser penilaian dari risiko ke ketidakpastian dalam kerangka P90–P10.', 'input': '', 'output': '## Pengaruh Teknologi Produksi terhadap Keyakinan Alir Konklusif dan Perubahan Penilaian Risiko ke Ketidakpastian\\n\\nTeknologi produksi, seperti fracking, memiliki pengaruh signifikan terhadap keyakinan alir konklusif dalam proyek eksplorasi migas. Dalam konteks eksplorasi, alir konklusif merujuk pada kemampuan fluida petroleum untuk mengalir secara terus-menerus ke permukaan. Pada tahap awal eksplorasi, keyakinan terhadap kemampuan alir ini sering kali terbatas karena kurangnya data atau uji sumur yang memadai. Namun, penerapan teknologi produksi yang tepat dapat meningkatkan keyakinan bahwa fluida dapat mengalir secara berkelanjutan, bahkan dalam kondisi reservoir yang kompleks, seperti minyak berat atau sumber daya non-konvensional. Teknologi seperti fracking memungkinkan rekahan buatan pada batuan reservoir, sehingga meningkatkan permeabilitas dan memungkinkan fluida mengalir ke permukaan secara lebih efisien.\\n\\nKetika teknologi produksi berhasil diterapkan, status proyek dapat berubah dari tingkat ketidakpastian tinggi, seperti *Inconclusive Flow*, menuju tingkat yang lebih pasti seperti *Discovery under Evaluation*. Pada tahap ini, keyakinan terhadap kemampuan reservoir untuk menghasilkan fluida secara berkelanjutan meningkat, yang biasanya dikonfirmasi melalui uji sumur atau evaluasi teknis lainnya. Perubahan status ini mencerminkan bahwa risiko geologi—yang sebelumnya mendominasi penilaian proyek—telah berkurang, sementara fokus bergeser pada ketidakpastian teknis terkait volume sumber daya yang dapat diproduksi.\\n\\n### Perubahan Penilaian dari Risiko ke Ketidakpastian dalam Kerangka P90–P10\\n\\nDalam kerangka probabilistik P90–P10, teknologi produksi seperti fracking berperan dalam mengurangi risiko eksplorasi dengan memastikan keberadaan fluida yang dapat mengalir. Risiko eksplorasi, seperti apakah reservoir memiliki akumulasi petroleum yang ekonomis, berkurang ketika teknologi produksi menunjukkan keberhasilan. Setelah risiko ini berkurang, perhatian bergeser pada ketidakpastian teknis yang berkaitan dengan estimasi volume sumber daya. Ketidakpastian ini dievaluasi menggunakan pendekatan statistik, di mana estimasi bawah (P90), estimasi terbaik (P50), dan estimasi atas (P10) menggambarkan rentang volume yang mungkin diproduksi.\\n\\nSebagai contoh, setelah teknologi fracking diterapkan dan alir konklusif dikonfirmasi, probabilitas keberhasilan sistem petroleum meningkat. Namun, ketidakpastian tetap ada dalam menentukan volume yang dapat diproduksi secara komersial. Dalam hal ini, estimasi P90 menunjukkan volume minimum yang hampir pasti dapat diambil, sementara P50 dan P10 memberikan gambaran yang lebih optimis tentang potensi produksi. Dengan demikian, teknologi produksi mengurangi risiko eksplorasi, tetapi tidak menghilangkan ketidakpastian teknis yang menjadi fokus utama dalam tahap evaluasi sumber daya.\\n\\n### Kesimpulan\\n\\nTeknologi produksi seperti fracking memainkan peran penting dalam meningkatkan keyakinan terhadap kemampuan reservoir untuk menghasilkan fluida secara berkelanjutan, yang pada akhirnya mengubah status proyek eksplorasi. Perubahan ini menggeser fokus dari risiko eksplorasi ke ketidakpastian teknis terkait volume sumber daya, yang dievaluasi dalam kerangka probabilistik P90–P10. Dengan penerapan teknologi yang tepat, proyek dapat bergerak menuju tingkat kematangan yang lebih tinggi, sekaligus memberikan dasar yang lebih kuat untuk perencanaan pengembangan lapangan.', 'complexity': 0.6310545531, 'input_length': 73, 'output_length': 970, 'dominant_topic': 16, 'topic_keywords': 'discovery, sumur, uji, teknologi, evaluation', 'topic_name': 'discovery, sumur, uji, teknologi, evaluation'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'file_name', 'instruction', 'input', 'output', 'complexity', 'input_length', 'output_length', 'dominant_topic', 'topic_keywords', 'topic_name'],\n",
       "    num_rows: 247\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data = combined_data['val']\n",
    "dataset_size = len(combined_data['val'])\n",
    "print(combined_data['val'][0])\n",
    "eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3dd1788",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = eval_data.rename_column(\"instruction\", \"prompt\")\n",
    "eval_data = eval_data.rename_column(\"output\", \"response\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6df30301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Mengapa suatu proyek bisa mengalami project level maturity X2. Development Undetermined?', 'output': 'Suatu proyek dapat berada pada level maturity X2. Development Undetermined apabila belum mendapatkan persetujuan Penentuan Status Eksplorasi (PSE) atau belum memiliki Rencana Pengembangan (POD) yang disetujui SKK Migas. Kondisi ini menunjukkan bahwa proyek memerlukan data tambahan untuk menentukan status komersialitasnya.\\n\\nBeberapa faktor yang dapat menyebabkan proyek berada pada level X2 antara lain:\\n\\nBeralih dari level X1. Discovery under Evaluation\\nProyek belum memiliki kajian teknis yang memadai, misalnya data subsurface yang belum lengkap atau terverifikasi.\\n\\nBeralih dari level X0. Development Pending, dengan kendala sebagai berikut:\\n\\nEvaluasi keekonomian belum selesai atau belum memenuhi ambang batas kelayakan investasi.\\n\\nKajian teknis belum memadai, seperti keterbatasan data subsurface atau desain fasilitas produksi yang belum lengkap atau terverifikasi.\\n\\nAdanya isu strategis atau regulasi yang menyebabkan proses persetujuan POD tertunda atau dihentikan sementara.', 'dominant_topic': 4, 'topic_keywords': 'pengembangan, eksplorasi, development, fase, berproduksi', 'topic_name': 'pengembangan, eksplorasi, development, fase, berproduksi'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'output', 'dominant_topic', 'topic_keywords', 'topic_name'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = combined_data['test']\n",
    "dataset_size = len(combined_data['test'])\n",
    "print(combined_data['test'][randrange(dataset_size)])\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e61b331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89cdf158",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.rename_column(\"instruction\", \"prompt\")\n",
    "test_data = test_data.rename_column(\"output\", \"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fcc6c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'response', 'dominant_topic', 'topic_keywords', 'topic_name'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60860936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "916bad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL_NAME = \"Qwen/Qwen3-4B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47318b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define max memory to force CPU offloading if needed\n",
    "max_memory = {0: \"3.5GiB\", \"cpu\": \"30GiB\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53819339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_gpu_memory():\n",
    "    \"\"\"Aggressively clear GPU memory cache\"\"\"\n",
    "    print(\"--- Clearing GPU memory ---\")\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    if torch.cuda.is_available():\n",
    "        print(\n",
    "            f\"GPU memory allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "        print(\n",
    "            f\"GPU memory reserved: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be392d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a robust quantization configuration\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f35a3442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(\n",
    "    model_to_load,\n",
    "    adapter_path=None,\n",
    "    prompts = None,\n",
    "    max_new_tokens=1024,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    enable_thinking=False,\n",
    "    do_stream=True,\n",
    "):\n",
    "    print(f\"\\n--- Loading model: {model_to_load} ---\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_to_load)\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_to_load,\n",
    "        device_map=\"auto\",\n",
    "        quantization_config=bnb_config,\n",
    "        max_memory=max_memory,\n",
    "        dtype=torch.bfloat16,\n",
    "    )\n",
    "\n",
    "    if adapter_path:\n",
    "        print(f\"--- Applying LoRA adapter from: {adapter_path} ---\")\n",
    "        model = PeftModel.from_pretrained(model, adapter_path)\n",
    "\n",
    "    responses = []\n",
    "\n",
    "    # ========================================================\n",
    "    # LOOP THROUGH ALL PROMPTS GIVEN\n",
    "    # ========================================================\n",
    "    for prompt_text in prompts:\n",
    "        print(f\"\\n========== PROMPT ==========\\n{prompt_text}\\n\")\n",
    "\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt_text}]\n",
    "        input_text = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "            enable_thinking=enable_thinking,\n",
    "        )\n",
    "\n",
    "        model_inputs = tokenizer(\n",
    "            input_text, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if do_stream:\n",
    "                print(\"Streaming response:\\n\")\n",
    "                streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "                _ = model.generate(\n",
    "                    **model_inputs,\n",
    "                    max_new_tokens=max_new_tokens,\n",
    "                    temperature=temperature,\n",
    "                    top_p=top_p,\n",
    "                    do_sample=(temperature > 0),\n",
    "                    streamer=streamer,\n",
    "                    pad_token_id=tokenizer.eos_token_id,\n",
    "                )\n",
    "\n",
    "                end_time = time.time()\n",
    "                print(\n",
    "                    f\"\\n[Streamed Answer Took {end_time - start_time:.2f} sec]\")\n",
    "\n",
    "                responses.append(\n",
    "                    {\"prompt\": prompt_text, \"response\": \"(streamed)\"})\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                generated_ids = model.generate(\n",
    "                    **model_inputs,\n",
    "                    max_new_tokens=max_new_tokens,\n",
    "                    temperature=temperature,\n",
    "                    top_p=top_p,\n",
    "                    do_sample=(temperature > 0),\n",
    "                    pad_token_id=tokenizer.eos_token_id,\n",
    "                )\n",
    "\n",
    "                prompt_len = model_inputs.input_ids.shape[-1]\n",
    "                new_ids = generated_ids[0][prompt_len:]\n",
    "                text = tokenizer.decode(new_ids, skip_special_tokens=True)\n",
    "\n",
    "                end_time = time.time()\n",
    "                tps = len(new_ids) / (end_time - start_time)\n",
    "\n",
    "                print(\n",
    "                    f\"[Answer Took {end_time - start_time:.2f} sec, TPS={tps:.2f}]\")\n",
    "                print(\"\\nRESPONSE:\\n\", text)\n",
    "\n",
    "                responses.append({\"prompt\": prompt_text, \"response\": text})\n",
    "\n",
    "    # Cleanup\n",
    "    del model\n",
    "    del tokenizer\n",
    "    clear_gpu_memory()\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7901ad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SFTConfig(\n",
    "    model_name=BASE_MODEL_NAME,\n",
    "    num_epochs=3,\n",
    "    use_lora=True,\n",
    "    lora_r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    prompt_column=\"prompt\",\n",
    "    response_column=\"response\",\n",
    "    output_dir=\"./Qwen3-4B-sft-output\",\n",
    "\n",
    "    enable_evaluation=True,\n",
    "    evaluation_dataset=eval_data,\n",
    "    evaluation_metrics=[\"perplexity\", \"semantic_entropy\", \"token_entropy\"],\n",
    "    evaluation_batch_size=2,\n",
    "    save_evaluation_results=True,\n",
    "    evaluation_results_path=\"./evaluation_results.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c934b952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Clearing GPU memory ---\n",
      "GPU memory allocated: 0.00 GB\n",
      "GPU memory reserved: 0.00 GB\n",
      "\n",
      "==================================================\n",
      "         STARTING FINE-TUNING\n",
      "==================================================\n",
      "Note: This may be slow on a 4GB GPU due to RAM-CPU offloading, but it will work.\n",
      "✅ Quantization enabled: nf4 with bfloat16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 3 files:   0%|          | 0/3 [13:30<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\tqdm\\contrib\\concurrent.py:51\u001b[39m, in \u001b[36m_executor_map\u001b[39m\u001b[34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m PoolExecutor(max_workers=max_workers, initializer=tqdm_class.set_lock,\n\u001b[32m     50\u001b[39m                   initargs=(lk,)) \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:619\u001b[39m, in \u001b[36mExecutor.map.<locals>.result_iterator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    618\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:317\u001b[39m, in \u001b[36m_result_or_cancel\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:451\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__get_result()\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_condition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:327\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m     gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m50\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNote: This may be slow on a 4GB GPU due to RAM-CPU offloading, but it will work.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m trainer = \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msft\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m trainer.train(train_data)\n\u001b[32m     12\u001b[39m trainer.save_model()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\WebDev\\transfer\\transfer\\trainer.py:76\u001b[39m, in \u001b[36mTrainer.__init__\u001b[39m\u001b[34m(self, task, config)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.task \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._strategies:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     74\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTask \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.task\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m not supported. Choose from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m._strategies.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.tokenizer = \u001b[43mload_model_and_tokenizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbnb_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_dtype\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# --- LoRA LOGIC ---\u001b[39;00m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_lora:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\WebDev\\transfer\\transfer\\utils.py:8\u001b[39m, in \u001b[36mload_model_and_tokenizer\u001b[39m\u001b[34m(model_name, dtype, quantization_config)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Loads a model and tokenizer with standard settings.\"\"\"\u001b[39;00m\n\u001b[32m      7\u001b[39m tokenizer = AutoTokenizer.from_pretrained(model_name)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model, tokenizer\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:604\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    602\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    603\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    608\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    609\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    610\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:277\u001b[39m, in \u001b[36mrestore_default_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    275\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    279\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:4900\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4890\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4891\u001b[39m     gguf_file\n\u001b[32m   4892\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4893\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m ((\u001b[38;5;28misinstance\u001b[39m(device_map, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map.values()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map)\n\u001b[32m   4894\u001b[39m ):\n\u001b[32m   4895\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   4896\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOne or more modules is configured to be mapped to disk. Disk offload is not supported for models \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4897\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mloaded from GGUF files.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4898\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m4900\u001b[39m checkpoint_files, sharded_metadata = \u001b[43m_get_resolved_checkpoint_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4901\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4902\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4903\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4904\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4905\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4906\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4907\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4908\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4909\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4910\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4911\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4912\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4913\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4914\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_auto_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   4917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4918\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4920\u001b[39m is_sharded = sharded_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4921\u001b[39m is_quantized = hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:1200\u001b[39m, in \u001b[36m_get_resolved_checkpoint_files\u001b[39m\u001b[34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, is_remote_code, transformers_explicit_filename)\u001b[39m\n\u001b[32m   1198\u001b[39m sharded_metadata = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1199\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_sharded:\n\u001b[32m-> \u001b[39m\u001b[32m1200\u001b[39m     checkpoint_files, sharded_metadata = \u001b[43mget_checkpoint_shard_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1206\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1209\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1212\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1213\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1214\u001b[39m     checkpoint_files = [resolved_archive_file] \u001b[38;5;28;01mif\u001b[39;00m pretrained_model_name_or_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:1084\u001b[39m, in \u001b[36mget_checkpoint_shard_files\u001b[39m\u001b[34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, token, user_agent, revision, subfolder, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m   1080\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m shard_filenames, sharded_metadata\n\u001b[32m   1082\u001b[39m \u001b[38;5;66;03m# At this stage pretrained_model_name_or_path is a model identifier on the Hub. Try to get everything from cache,\u001b[39;00m\n\u001b[32m   1083\u001b[39m \u001b[38;5;66;03m# or download the files\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1084\u001b[39m cached_filenames = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1085\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1086\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshard_filenames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1087\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1088\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1089\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1091\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1093\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1094\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1096\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1097\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1099\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cached_filenames, sharded_metadata\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:494\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    479\u001b[39m         hf_hub_download(\n\u001b[32m    480\u001b[39m             path_or_repo_id,\n\u001b[32m    481\u001b[39m             filenames[\u001b[32m0\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    491\u001b[39m             local_files_only=local_files_only,\n\u001b[32m    492\u001b[39m         )\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m         \u001b[43msnapshot_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m            \u001b[49m\u001b[43mallow_patterns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfull_filenames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    509\u001b[39m     \u001b[38;5;66;03m# We cannot recover from them\u001b[39;00m\n\u001b[32m    510\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, RepositoryNotFoundError) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, GatedRepoError):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\huggingface_hub\\_snapshot_download.py:332\u001b[39m, in \u001b[36msnapshot_download\u001b[39m\u001b[34m(repo_id, repo_type, revision, cache_dir, local_dir, library_name, library_version, user_agent, proxies, etag_timeout, force_download, token, local_files_only, allow_patterns, ignore_patterns, max_workers, tqdm_class, headers, endpoint, local_dir_use_symlinks, resume_download)\u001b[39m\n\u001b[32m    330\u001b[39m         _inner_hf_hub_download(file)\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m     \u001b[43mthread_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_inner_hf_hub_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfiltered_repo_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_desc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# User can use its own tqdm class or the default one from `huggingface_hub.utils`\u001b[39;49;00m\n\u001b[32m    338\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhf_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m local_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    342\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(os.path.realpath(local_dir))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\tqdm\\contrib\\concurrent.py:69\u001b[39m, in \u001b[36mthread_map\u001b[39m\u001b[34m(fn, *iterables, **tqdm_kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[33;03mEquivalent of `list(map(fn, *iterables))`\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[33;03mdriven by `concurrent.futures.ThreadPoolExecutor`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     66\u001b[39m \u001b[33;03m    [default: max(32, cpu_count() + 4)].\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mconcurrent\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfutures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ThreadPoolExecutor\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_executor_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mThreadPoolExecutor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\tqdm\\contrib\\concurrent.py:49\u001b[39m, in \u001b[36m_executor_map\u001b[39m\u001b[34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m lock_name = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mlock_name\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ensure_lock(tqdm_class, lock_name=lock_name) \u001b[38;5;28;01mas\u001b[39;00m lk:\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# share lock in case workers are already using `tqdm`\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mPoolExecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitializer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_lock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m                      \u001b[49m\u001b[43minitargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mex\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:647\u001b[39m, in \u001b[36mExecutor.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_val, exc_tb)\u001b[39m\n\u001b[32m    646\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    648\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\thread.py:235\u001b[39m, in \u001b[36mThreadPoolExecutor.shutdown\u001b[39m\u001b[34m(self, wait, cancel_futures)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[32m    234\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._threads:\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m         \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:1119\u001b[39m, in \u001b[36mThread.join\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1116\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot join current thread\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1119\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1120\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1121\u001b[39m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[32m   1122\u001b[39m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[32m   1123\u001b[39m     \u001b[38;5;28mself\u001b[39m._wait_for_tstate_lock(timeout=\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[32m0\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:1139\u001b[39m, in \u001b[36mThread._wait_for_tstate_lock\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m   1136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1138\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1139\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1140\u001b[39m         lock.release()\n\u001b[32m   1141\u001b[39m         \u001b[38;5;28mself\u001b[39m._stop()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py:128\u001b[39m, in \u001b[36m_pseudo_sync_runner\u001b[39m\u001b[34m(coro)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[33;03mA runner that does not really allow async execution, and just advance the coroutine.\u001b[39;00m\n\u001b[32m    122\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    125\u001b[39m \u001b[33;03mCredit to Nathaniel Smith\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc.value\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3413\u001b[39m, in \u001b[36mInteractiveShell.run_cell_async\u001b[39m\u001b[34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple, cell_id)\u001b[39m\n\u001b[32m   3409\u001b[39m exec_count = \u001b[38;5;28mself\u001b[39m.execution_count\n\u001b[32m   3410\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.error_in_exec:\n\u001b[32m   3411\u001b[39m     \u001b[38;5;66;03m# Store formatted traceback and error details\u001b[39;00m\n\u001b[32m   3412\u001b[39m     \u001b[38;5;28mself\u001b[39m.history_manager.exceptions[exec_count] = (\n\u001b[32m-> \u001b[39m\u001b[32m3413\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_format_exception_for_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror_in_exec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3414\u001b[39m     )\n\u001b[32m   3416\u001b[39m \u001b[38;5;66;03m# Each cell is a *single* input, regardless of how many lines it has\u001b[39;00m\n\u001b[32m   3417\u001b[39m \u001b[38;5;28mself\u001b[39m.execution_count += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3467\u001b[39m, in \u001b[36mInteractiveShell._format_exception_for_storage\u001b[39m\u001b[34m(self, exception, filename, running_compiled_code)\u001b[39m\n\u001b[32m   3464\u001b[39m         stb = evalue._render_traceback_()\n\u001b[32m   3465\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3466\u001b[39m         \u001b[38;5;66;03m# Otherwise, use InteractiveTB to format the traceback.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3467\u001b[39m         stb = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mInteractiveTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3468\u001b[39m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   3469\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3470\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   3471\u001b[39m     \u001b[38;5;66;03m# In case formatting fails, fallback to Python's built-in formatting.\u001b[39;00m\n\u001b[32m   3472\u001b[39m     stb = traceback.format_exception(etype, evalue, tb)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\IPython\\core\\ultratb.py:1188\u001b[39m, in \u001b[36mAutoFormattedTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m   1186\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1187\u001b[39m     \u001b[38;5;28mself\u001b[39m.tb = etb\n\u001b[32m-> \u001b[39m\u001b[32m1188\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\IPython\\core\\ultratb.py:1059\u001b[39m, in \u001b[36mFormattedTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m   1056\u001b[39m mode = \u001b[38;5;28mself\u001b[39m.mode\n\u001b[32m   1057\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose_modes:\n\u001b[32m   1058\u001b[39m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1059\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1061\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1062\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mDocs\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1063\u001b[39m     \u001b[38;5;66;03m# return DocTB\u001b[39;00m\n\u001b[32m   1064\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DocTB(\n\u001b[32m   1065\u001b[39m         theme_name=\u001b[38;5;28mself\u001b[39m._theme_name,\n\u001b[32m   1066\u001b[39m         call_pdb=\u001b[38;5;28mself\u001b[39m.call_pdb,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1074\u001b[39m         etype, evalue, etb, tb_offset, \u001b[32m1\u001b[39m\n\u001b[32m   1075\u001b[39m     )  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\IPython\\core\\ultratb.py:867\u001b[39m, in \u001b[36mVerboseTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m    858\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstructured_traceback\u001b[39m(\n\u001b[32m    859\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    860\u001b[39m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    864\u001b[39m     context: \u001b[38;5;28mint\u001b[39m = \u001b[32m5\u001b[39m,\n\u001b[32m    865\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    866\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m867\u001b[39m     formatted_exceptions: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m        \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    871\u001b[39m     termsize = \u001b[38;5;28mmin\u001b[39m(\u001b[32m75\u001b[39m, get_terminal_size()[\u001b[32m0\u001b[39m])\n\u001b[32m    872\u001b[39m     theme = theme_table[\u001b[38;5;28mself\u001b[39m._theme_name]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\IPython\\core\\ultratb.py:779\u001b[39m, in \u001b[36mVerboseTB.format_exception_as_a_whole\u001b[39m\u001b[34m(self, etype, evalue, etb, context, tb_offset)\u001b[39m\n\u001b[32m    769\u001b[39m         frames.append(\n\u001b[32m    770\u001b[39m             theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m    771\u001b[39m                 [\n\u001b[32m   (...)\u001b[39m\u001b[32m    776\u001b[39m             )\n\u001b[32m    777\u001b[39m         )\n\u001b[32m    778\u001b[39m         skipped = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m779\u001b[39m     frames.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    780\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m skipped:\n\u001b[32m    781\u001b[39m     frames.append(\n\u001b[32m    782\u001b[39m         theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m    783\u001b[39m             [\n\u001b[32m   (...)\u001b[39m\u001b[32m    788\u001b[39m         )\n\u001b[32m    789\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\IPython\\core\\ultratb.py:654\u001b[39m, in \u001b[36mVerboseTB.format_record\u001b[39m\u001b[34m(self, frame_info)\u001b[39m\n\u001b[32m    651\u001b[39m result += \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m call \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    652\u001b[39m result += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcall\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    653\u001b[39m result += theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m--> \u001b[39m\u001b[32m654\u001b[39m     \u001b[43m_format_traceback_lines\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtheme_table\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_theme_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhas_colors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlvals_toks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    660\u001b[39m )\n\u001b[32m    661\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\IPython\\core\\tbtools.py:99\u001b[39m, in \u001b[36m_format_traceback_lines\u001b[39m\u001b[34m(lines, theme, has_colors, lvals_toks)\u001b[39m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     98\u001b[39m lineno = stack_line.lineno\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m line = \u001b[43mstack_line\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpygmented\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_colors\u001b[49m\u001b[43m)\u001b[49m.rstrip(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m) + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stack_line.is_current:\n\u001b[32m    101\u001b[39m     \u001b[38;5;66;03m# This is the line with the error\u001b[39;00m\n\u001b[32m    102\u001b[39m     pad = numbers_width - \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mstr\u001b[39m(lineno))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\stack_data\\core.py:391\u001b[39m, in \u001b[36mLine.render\u001b[39m\u001b[34m(self, markers, strip_leading_indent, pygmented, escape_html)\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pygmented \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.frame_info.scope:\n\u001b[32m    390\u001b[39m     assert_(\u001b[38;5;129;01mnot\u001b[39;00m markers, \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot use pygmented with markers\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m     start_line, lines = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mframe_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_pygmented_scope_lines\u001b[49m\n\u001b[32m    392\u001b[39m     result = lines[\u001b[38;5;28mself\u001b[39m.lineno - start_line]\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m strip_leading_indent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\stack_data\\utils.py:145\u001b[39m, in \u001b[36mcached_property.cached_property_wrapper\u001b[39m\u001b[34m(self, obj, _cls)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m value = obj.\u001b[34m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m.func.\u001b[34m__name__\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\stack_data\\core.py:824\u001b[39m, in \u001b[36mFrameInfo._pygmented_scope_lines\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    821\u001b[39m     ranges = []\n\u001b[32m    823\u001b[39m code = atext.get_text(scope)\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m lines = \u001b[43m_pygmented_with_ranges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranges\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    826\u001b[39m start_line = \u001b[38;5;28mself\u001b[39m.source.line_range(scope)[\u001b[32m0\u001b[39m]\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m start_line, lines\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\stack_data\\utils.py:164\u001b[39m, in \u001b[36m_pygmented_with_ranges\u001b[39m\u001b[34m(formatter, code, ranges)\u001b[39m\n\u001b[32m    161\u001b[39m             length += \u001b[38;5;28mlen\u001b[39m(value)\n\u001b[32m    162\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m ttype, value\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m lexer = \u001b[43mMyLexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstripnl\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    166\u001b[39m     highlighted = pygments.highlight(code, lexer, formatter)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\pygments\\lexer.py:660\u001b[39m, in \u001b[36mRegexLexerMeta.__call__\u001b[39m\u001b[34m(cls, *args, **kwds)\u001b[39m\n\u001b[32m    658\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m660\u001b[39m         \u001b[38;5;28mcls\u001b[39m._tokens = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess_tokendef\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_tokendefs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m.\u001b[34m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, *args, **kwds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\pygments\\lexer.py:599\u001b[39m, in \u001b[36mRegexLexerMeta.process_tokendef\u001b[39m\u001b[34m(cls, name, tokendefs)\u001b[39m\n\u001b[32m    597\u001b[39m tokendefs = tokendefs \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.tokens[name]\n\u001b[32m    598\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m state \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(tokendefs):\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokendefs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m processed\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\pygments\\lexer.py:563\u001b[39m, in \u001b[36mRegexLexerMeta._process_state\u001b[39m\u001b[34m(cls, unprocessed, processed, state)\u001b[39m\n\u001b[32m    560\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tdef, include):\n\u001b[32m    561\u001b[39m     \u001b[38;5;66;03m# it's a state reference\u001b[39;00m\n\u001b[32m    562\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m tdef != state, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcircular state reference \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m     tokens.extend(\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43munprocessed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtdef\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    565\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    566\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tdef, _inherit):\n\u001b[32m    567\u001b[39m     \u001b[38;5;66;03m# should be processed already, but may not in the case of:\u001b[39;00m\n\u001b[32m    568\u001b[39m     \u001b[38;5;66;03m# 1. the state has no counterpart in any parent\u001b[39;00m\n\u001b[32m    569\u001b[39m     \u001b[38;5;66;03m# 2. the state includes more than one 'inherit'\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\pygments\\lexer.py:563\u001b[39m, in \u001b[36mRegexLexerMeta._process_state\u001b[39m\u001b[34m(cls, unprocessed, processed, state)\u001b[39m\n\u001b[32m    560\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tdef, include):\n\u001b[32m    561\u001b[39m     \u001b[38;5;66;03m# it's a state reference\u001b[39;00m\n\u001b[32m    562\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m tdef != state, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcircular state reference \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m     tokens.extend(\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43munprocessed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtdef\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    565\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    566\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tdef, _inherit):\n\u001b[32m    567\u001b[39m     \u001b[38;5;66;03m# should be processed already, but may not in the case of:\u001b[39;00m\n\u001b[32m    568\u001b[39m     \u001b[38;5;66;03m# 1. the state has no counterpart in any parent\u001b[39;00m\n\u001b[32m    569\u001b[39m     \u001b[38;5;66;03m# 2. the state includes more than one 'inherit'\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\pygments\\lexer.py:579\u001b[39m, in \u001b[36mRegexLexerMeta._process_state\u001b[39m\u001b[34m(cls, unprocessed, processed, state)\u001b[39m\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tdef) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwrong rule def \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtdef\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m     rex = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_regex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtdef\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    581\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33muncompilable regex \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtdef[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m in state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\pygments\\lexer.py:507\u001b[39m, in \u001b[36mRegexLexerMeta._process_regex\u001b[39m\u001b[34m(cls, regex, rflags, state)\u001b[39m\n\u001b[32m    505\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Preprocess the regular expression component of a token definition.\"\"\"\u001b[39;00m\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(regex, Future):\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m     regex = \u001b[43mregex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m re.compile(regex, rflags).match\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\pygments\\lexer.py:495\u001b[39m, in \u001b[36mwords.get\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mregex_opt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\pygments\\regexopt.py:91\u001b[39m, in \u001b[36mregex_opt\u001b[39m\u001b[34m(strings, prefix, suffix)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return a compiled regex that matches any string in the given list.\u001b[39;00m\n\u001b[32m     84\u001b[39m \n\u001b[32m     85\u001b[39m \u001b[33;03mThe strings to match must be literal strings, not regexes.  They will be\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     88\u001b[39m \u001b[33;03m*prefix* and *suffix* are pre- and appended to the final regex.\u001b[39;00m\n\u001b[32m     89\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     90\u001b[39m strings = \u001b[38;5;28msorted\u001b[39m(strings)\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m prefix + \u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m(\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m + suffix\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\pygments\\regexopt.py:77\u001b[39m, in \u001b[36mregex_opt_inner\u001b[39m\u001b[34m(strings, open_paren)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren \\\n\u001b[32m     72\u001b[39m         + regex_opt_inner(\u001b[38;5;28msorted\u001b[39m(s[:-slen] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings), \u001b[33m'\u001b[39m\u001b[33m(?:\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     73\u001b[39m         + escape(suffix[::-\u001b[32m1\u001b[39m]) + close_paren\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# recurse on common 1-string prefixes\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# print '-> last resort'\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \\\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m|\u001b[39m\u001b[33m'\u001b[39m.join(regex_opt_inner(\u001b[38;5;28mlist\u001b[39m(group[\u001b[32m1\u001b[39m]), \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     78\u001b[39m              \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m groupby(strings, \u001b[38;5;28;01mlambda\u001b[39;00m s: s[\u001b[32m0\u001b[39m] == first[\u001b[32m0\u001b[39m])) \\\n\u001b[32m     79\u001b[39m     + close_paren\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\pygments\\regexopt.py:77\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren \\\n\u001b[32m     72\u001b[39m         + regex_opt_inner(\u001b[38;5;28msorted\u001b[39m(s[:-slen] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings), \u001b[33m'\u001b[39m\u001b[33m(?:\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     73\u001b[39m         + escape(suffix[::-\u001b[32m1\u001b[39m]) + close_paren\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# recurse on common 1-string prefixes\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# print '-> last resort'\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \\\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m|\u001b[39m\u001b[33m'\u001b[39m.join(\u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m              \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m groupby(strings, \u001b[38;5;28;01mlambda\u001b[39;00m s: s[\u001b[32m0\u001b[39m] == first[\u001b[32m0\u001b[39m])) \\\n\u001b[32m     79\u001b[39m     + close_paren\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\pygments\\regexopt.py:77\u001b[39m, in \u001b[36mregex_opt_inner\u001b[39m\u001b[34m(strings, open_paren)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren \\\n\u001b[32m     72\u001b[39m         + regex_opt_inner(\u001b[38;5;28msorted\u001b[39m(s[:-slen] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings), \u001b[33m'\u001b[39m\u001b[33m(?:\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     73\u001b[39m         + escape(suffix[::-\u001b[32m1\u001b[39m]) + close_paren\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# recurse on common 1-string prefixes\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# print '-> last resort'\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \\\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m|\u001b[39m\u001b[33m'\u001b[39m.join(regex_opt_inner(\u001b[38;5;28mlist\u001b[39m(group[\u001b[32m1\u001b[39m]), \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     78\u001b[39m              \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m groupby(strings, \u001b[38;5;28;01mlambda\u001b[39;00m s: s[\u001b[32m0\u001b[39m] == first[\u001b[32m0\u001b[39m])) \\\n\u001b[32m     79\u001b[39m     + close_paren\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\pygments\\regexopt.py:77\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m open_paren \\\n\u001b[32m     72\u001b[39m         + regex_opt_inner(\u001b[38;5;28msorted\u001b[39m(s[:-slen] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m strings), \u001b[33m'\u001b[39m\u001b[33m(?:\u001b[39m\u001b[33m'\u001b[39m) \\\n\u001b[32m     73\u001b[39m         + escape(suffix[::-\u001b[32m1\u001b[39m]) + close_paren\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# recurse on common 1-string prefixes\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# print '-> last resort'\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + \\\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m|\u001b[39m\u001b[33m'\u001b[39m.join(\u001b[43mregex_opt_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m              \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m groupby(strings, \u001b[38;5;28;01mlambda\u001b[39;00m s: s[\u001b[32m0\u001b[39m] == first[\u001b[32m0\u001b[39m])) \\\n\u001b[32m     79\u001b[39m     + close_paren\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HiDigi\\OneDrive\\Desktop\\WebDev\\transfer\\.venv\\Lib\\site-packages\\pygments\\regexopt.py:57\u001b[39m, in \u001b[36mregex_opt_inner\u001b[39m\u001b[34m(strings, open_paren)\u001b[39m\n\u001b[32m     55\u001b[39m         \u001b[38;5;66;03m# print '-> only 1-character'\u001b[39;00m\n\u001b[32m     56\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m open_paren + make_charset(oneletter) + close_paren\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m prefix = \u001b[43mcommonprefix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prefix:\n\u001b[32m     59\u001b[39m     plen = \u001b[38;5;28mlen\u001b[39m(prefix)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen genericpath>:80\u001b[39m, in \u001b[36mcommonprefix\u001b[39m\u001b[34m(m)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Clear memory before training\n",
    "clear_gpu_memory()\n",
    "\n",
    "# === FINE-TUNING ===\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"         STARTING FINE-TUNING\")\n",
    "print(\"=\"*50)\n",
    "print(\"Note: This may be slow on a 4GB GPU due to RAM-CPU offloading, but it will work.\")\n",
    "\n",
    "trainer = Trainer(task=\"sft\", config=config)\n",
    "trainer.train(train_data)\n",
    "trainer.save_model()\n",
    "print(\"Fine-tuning complete. Model saved to:\", config.output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611c6c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de4b608",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TO_TEST = test_data[\"prompt\"]\n",
    "import random\n",
    "PROMPT_TO_TEST = random.sample(test_data[\"prompt\"], 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32cb383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === AFTER FINE-TUNING ===\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"        INFERENCE AFTER FINE-TUNING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "response_after = run_inference(\n",
    "    BASE_MODEL_NAME, adapter_path=config.output_dir, prompts=PROMPT_TO_TEST, do_stream=True)\n",
    "# for r in response_after:\n",
    "#     print(f\"Prompt: {r['prompt']}\\nResponse: {r['response']}\\n\")\n",
    "\n",
    "# Final cleanup\n",
    "clear_gpu_memory()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transfer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
